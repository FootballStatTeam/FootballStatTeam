{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from csv import DictWriter\n",
    "\n",
    "DOMAIN=\"https://fbref.com\"\n",
    "URL = 'https://fbref.com/en/countries/'\n",
    "\n",
    "response = rq.get(URL)\n",
    "\n",
    "def get_soup(url):\n",
    "    return bs(rq.get(url).text,\"html.parser\")\n",
    "\n",
    "soup=get_soup(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findtableworlcupmen(link):\n",
    "    if 'href' in link.attrs and link.text=='Men': #just Men\n",
    "        #print(str(DOMAIN+link.attrs['href'])+\"\\n\")\n",
    "        URLmen=DOMAIN+link.attrs['href']\n",
    "        #go to this page\n",
    "        response = rq.get(URLmen)\n",
    "        #print(URLmen)\n",
    "        soup=get_soup(URLmen) #page html du pays\n",
    "        table=soup.find('table',{'id':'comps_cup_1'})\n",
    "        return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findcountryandlinks(tr):\n",
    "    if tr.find('strong'):\n",
    "        country=tr.find('strong') #pays a enregistrer dans pandas\n",
    "        country=country.text\n",
    "        tds=tr.find('td',{\"data-stat\":\"national_teams\"})\n",
    "        #print(tds)\n",
    "        links=tds.find_all('a')\n",
    "        return country,links\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findsquad(row):\n",
    "    thannee=row.find('th') #annee a enregistrer dans pandas\n",
    "    annee=thannee.text\n",
    "    #print(thannee.text)\n",
    "    tdsannee=row.find('td',{'data-stat':\"squad\"})\n",
    "    return annee,tdsannee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savetablecsv(table,country,annee):\n",
    "    rows = table.find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        datematch=None\n",
    "        tdlinkmatch=None\n",
    "        dict_infos_match={}\n",
    "        for cell in row.findAll([\"td\", \"th\"]):\n",
    "            tdlinkmatch=row.find('td',{\"data-stat\":\"match_report\"})\n",
    "            date=row.find('th',{\"data-stat\":\"date\"})\n",
    "            opponent=row.find('td',{\"data-stat\":\"opponent\"})\n",
    "        #print(tdlinkmatch)\n",
    "        if tdlinkmatch!=None:\n",
    "            matchreportpage(tdlinkmatch,date,opponent,country) #dict with infos from match we add it to column in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchreporttables(soupmatch,dateexacte,opponentname,country):\n",
    "    #print(\"Country: \" + country + \" Opponent: \" + opponentname)\n",
    "    \n",
    "    divsmatch=soupmatch.find_all('div',{'class':'table_container current'})\n",
    "    #tablesmatch=soupmatch.find_all('table')\n",
    "    if divsmatch!=None:\n",
    "        #if (tablesmatch.find('table')!=None):\n",
    "        for div in divsmatch: #enregistrer chaque table sous format csv\n",
    "            #prendre caption de la table\n",
    "            #print(tab)\n",
    "            tab=div.find('table')\n",
    "            \n",
    "            if tab.caption!=None:\n",
    "                caption=tab.caption.text\n",
    "                \n",
    "                file= \"PlayersStatsMatch/\" + caption + \"_\" + dateexacte + \"_\" + opponentname + \"_PlayersMatch.csv\"\n",
    "                rows = tab.find_all(\"tr\")\n",
    "                with open(file, \"wt+\", encoding=\"utf-8\",newline=\"\") as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    for row in rows:\n",
    "                        csv_row = []\n",
    "                        for cell in row.findAll([\"td\", \"th\"]):\n",
    "                            csv_row.append(cell.get_text())\n",
    "\n",
    "                        writer.writerow(csv_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchreportpage(tdlinkmatch,date,opponent,country):\n",
    "     #take a href \n",
    "     #DOMAIN+\"en/matches/16253d86/Belarus-France-September-6-2016-WCQ----UEFA-M\"\n",
    "    if 'href' in tdlinkmatch.find('a').attrs:\n",
    "        URLmatch=DOMAIN+tdlinkmatch.find('a').attrs['href']\n",
    "        #print(URLmatch)\n",
    "        #go to this page\n",
    "        response = rq.get(URLmatch)\n",
    "        #print(URLmen)\n",
    "        soupmatch=get_soup(URLmatch) #page html du match\n",
    "        #get date and egt opponent\n",
    "        if date.find('a'):\n",
    "            dateexacte=date.a.text\n",
    "            #print(dateexacte)\n",
    "        if opponent.find('a'):\n",
    "            opponentname=opponent.a.text\n",
    "            \n",
    "        matchreporttables(soupmatch,dateexacte,opponentname,country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findallstats(linkannee):\n",
    "    URLannee=DOMAIN+linkannee.attrs['href']\n",
    "    #print(URLannee)\n",
    "    response = rq.get(URLannee)\n",
    "    soupannee=get_soup(URLannee)\n",
    "    tableannee=soupannee.find('table',{'id':'matchlogs_for'})\n",
    "    return tableannee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteratelines(trs):\n",
    "    for tr in trs:\n",
    "        #nom pays\n",
    "        if findcountryandlinks(tr)!=None:\n",
    "            country,links=findcountryandlinks(tr)\n",
    "            #trouver liens joueurs\n",
    "            if links!=None:\n",
    "                for link in links:\n",
    "                    table=findtableworlcupmen(link)\n",
    "                    if table!=None:\n",
    "                        for row in table.find_all('tr'):\n",
    "                            annee,tdsannee=findsquad(row)\n",
    "                            if tdsannee!=None:\n",
    "                                linksyear=tdsannee.find_all('a')\n",
    "                                #print(linksyear)\n",
    "                                for linkannee in linksyear:\n",
    "                                    #print(linkannee)\n",
    "                                    tableannee=findallstats(linkannee)\n",
    "                                    if tableannee!=None:\n",
    "                                        if annee>='2000':\n",
    "                                        \n",
    "                                            savetablecsv(tableannee,country,annee)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs=soup.find_all('tr')\n",
    "iteratelines(trs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
